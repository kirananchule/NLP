{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed65aa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\anaconda\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d06abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Hello welcome,to krish naik's NLP tutorial.\n",
    "please do watch the entire course! to become expert in NLP.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe54f471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello welcome,to krish naik's NLP tutorial.\n",
      "please do watch the entire course! to become expert in NLP.\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f5e5910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize   ###para to sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb1afdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b60514e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d7d695e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16f30da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Hello welcome,to krish naik's NLP tutorial.\",\n",
       " 'please do watch the entire course!',\n",
       " 'to become expert in NLP.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = sent_tokenize(corpus)\n",
    "print(type(documents))\n",
    "documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d54677c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello welcome,to krish naik's NLP tutorial.\n",
      "please do watch the entire course!\n",
      "to become expert in NLP.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f8693dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize  ###paragraph to word tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c7dd53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'krish',\n",
       " 'naik',\n",
       " \"'s\",\n",
       " 'NLP',\n",
       " 'tutorial',\n",
       " '.',\n",
       " 'please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "385ba770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'welcome', ',', 'to', 'krish', 'naik', \"'s\", 'NLP', 'tutorial', '.']\n",
      "['please', 'do', 'watch', 'the', 'entire', 'course', '!']\n",
      "['to', 'become', 'expert', 'in', 'NLP', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ccb99f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_tokenize(documents)  ##get error it is list u word_tokenize want string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd4cba1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'krish',\n",
       " 'naik',\n",
       " \"'\",\n",
       " 's',\n",
       " 'NLP',\n",
       " 'tutorial',\n",
       " '.',\n",
       " 'please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize \n",
    "wordpunct_tokenize(corpus) ##considerd ' as word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe2c77",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2140e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eat\",\"eating\",\"eaten\",\"programm\",\"programming\",\"programms\",\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a1418ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "##type of stemming porterstemmer\n",
    "\n",
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cea6fddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat---->eat\n",
      "eating---->eat\n",
      "eaten---->eaten\n",
      "programm---->programm\n",
      "programming---->program\n",
      "programms---->programm\n",
      "history---->histori\n"
     ]
    }
   ],
   "source": [
    "stemming = PorterStemmer()\n",
    "for word in words:\n",
    "    print(word+\"---->\"+stemming.stem(word))  ###disadvantage meaning of some word change hostory-->histori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5bc05c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congratulations')###disadvantage of stemming: meaning of some word change congratulations-->congratul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0716a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### type of stemming RegexpStemmer \n",
    "\n",
    "from nltk.stem import RegexpStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "280ad1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$',min=4)  ###you have to pass regular expression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8515102",
   "metadata": {},
   "source": [
    "reg_stemmer.stem(\"cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6bbdda70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8d46ac2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scar'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"scars\") ##$ sign decie which has to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39e338be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"eating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1da33a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "### snowball stremmer\n",
    "\n",
    "from nltk.stem import SnowballStemmer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7788d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "snwoball = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df1d277a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snwoball.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e6e0a834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snwoball.stem('fairly'),snwoball.stem('sportingly')  ###gives better result than porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0d17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244cc583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48e51554",
   "metadata": {},
   "source": [
    "## Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "faf08e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "146c5b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4759f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "75b2274d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "07f39082",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\",\"eaten\",\"eating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e9bcd299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'church'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('churches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6a476c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eating'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3cc26e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "eat\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(lemmatizer.lemmatize(word,pos ='v')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7a321b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##for each pos you will get outupust as per pos like noun verb adjective adverb\n",
    "'''\n",
    "pos Noun-n\n",
    "verb - v\n",
    "adjective - a\n",
    "adverb -r \n",
    "'''\n",
    "lemmatizer.lemmatize(\"doing\",pos ='v')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "49f7dafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doing'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"doing\",pos ='r')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2066253c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kiran anchule'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"kiran anchule\",pos ='n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9e44d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eat\",\"eating\",\"eaten\",\"programm\",\"programming\",\"programms\",\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "21c21a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "eat\n",
      "eat\n",
      "programm\n",
      "program\n",
      "programms\n",
      "history\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(lemmatizer.lemmatize(word,pos ='v'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dd368405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "eating\n",
      "eaten\n",
      "programm\n",
      "programming\n",
      "programms\n",
      "history\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(lemmatizer.lemmatize(word,pos ='r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bcc6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
